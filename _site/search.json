[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Wei Lun and I am currently a full time student at SMU MITB."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages were installed in the computer. If they were, they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#simple-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#simple-bar-chart",
    "title": "Hands-on Exercise 1",
    "section": "Simple Bar Chart",
    "text": "Simple Bar Chart\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#trellis-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#trellis-boxplot",
    "title": "Hands-on Exercise 1",
    "section": "Trellis Boxplot",
    "text": "Trellis Boxplot\n\nggplot(data=exam_data,\n       aes(y = MATHS, x= CLASS)) +\n  geom_boxplot() +\n  facet_wrap(~ GENDER)\n\n\n\n\n\nggplot(data=exam_data,\n       aes(y = MATHS, x= CLASS)) +\n  geom_boxplot() +\n  facet_wrap(~ GENDER, ncol=1, strip.position=\"right\")\n\n\n\n\n\nggplot(data=exam_data,\n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  facet_grid(GENDER ~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-On Excerise 5",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot)\n\n\n\n\n\nwine <- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-plot",
    "title": "Hands-On Excerise 5",
    "section": "Basic Plot",
    "text": "Basic Plot\n\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-plot-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-plot-1",
    "title": "Hands-On Excerise 5",
    "section": "Basic plot",
    "text": "Basic plot\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\nAdding title and subtitle. list() function enables adjustment to be made within the chart.\n\n#ggcorrplot is able to autofill x and y axis and slant the axis labels automatically\n#| fig-width: 7\n#| fig-height: 7\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#multiple-plots",
    "title": "Hands-On Excerise 5",
    "section": "Multiple Plots",
    "text": "Multiple Plots\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic",
    "title": "Hands-On Excerise 5",
    "section": "Basic",
    "text": "Basic\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#mixed-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#mixed-layout",
    "title": "Hands-On Excerise 5",
    "section": "Mixed Layout",
    "text": "Mixed Layout\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#adding-significant-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#adding-significant-test",
    "title": "Hands-On Excerise 5",
    "section": "Adding Significant Test",
    "text": "Adding Significant Test\n\nCompute p-values and confidence interval\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nUsing p.mat argument,\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reorder-a-corrgram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reorder-a-corrgram",
    "title": "Hands-On Excerise 5",
    "section": "Reorder a Corrgram",
    "text": "Reorder a Corrgram\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "In-Class Excerise 6",
    "section": "",
    "text": "The following R packages are installed and launched: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\npacman:: p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "title": "In-Class Excerise 6",
    "section": "2. Importing the Data",
    "text": "2. Importing the Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\nThe code chunk below imports eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\nkable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp (POSIXct format), source_country (ISO 3166-1 alpha-2 country code) and tz (timezone).\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "title": "In-Class Excerise 6",
    "section": "3. Data Preparation",
    "text": "3. Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. Note: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nTtidy tibble table post processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#calendar-heatmaps",
    "title": "In-Class Excerise 6",
    "section": "4. Calendar Heatmaps",
    "text": "4. Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          linewidth = 0.1) + \ntheme_tufte() + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk:\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n\nWe can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n4.1 Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, these steps are required:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nThe attack records of the top 4 countries are extracted from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte() + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cycle-plot",
    "title": "In-Class Excerise 6",
    "section": "5. Cycle Plot",
    "text": "5. Cycle Plot\nThis section is on how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n5.1 Data Preparation\nStep 1: Data Import\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\nStep 3: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\nStep 4: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n#When do you use ungroup()\n\n\n\n5.2 Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/In-Class_Ex03.html",
    "href": "In-Class_Ex/In-Class_Ex03/In-Class_Ex03.html",
    "title": "In-Class_Ex03",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded. They are tidyverse and ggiraph.\n\n#pacman::p_load(ggiralph, tidyverse)\n#Change to library because of error when running pacman::p_load(ggiralph)\nlibrary(ggiraph)\nlibrary(tidyverse)\n\nImporting Data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\np <- ggplot(data = exam_data,\n       aes(x = MATHS)) +\ngeom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "title": "In-Class Excerise 4",
    "section": "",
    "text": "pacman::p_load(plotly, DT, patchwork, ggstatsplot, readxl, performance, parameters, see, ggdist, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#collinearity",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#collinearity",
    "title": "In-Class Excerise 4",
    "section": "Collinearity",
    "text": "Collinearity\n\ncheck_c <- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#normality-assumption-test",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#normality-assumption-test",
    "title": "In-Class Excerise 4",
    "section": "Normality Assumption Test",
    "text": "Normality Assumption Test\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period,\n             data = car_resale)\n\n\ncheck_n <- check_normality(model1)\nplot(check_n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#homogeneity-of-variances-test",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#homogeneity-of-variances-test",
    "title": "In-Class Excerise 4",
    "section": "Homogeneity of Variances Test",
    "text": "Homogeneity of Variances Test\n\ncheck_h <- check_heteroscedasticity(model1)\nplot(check_h)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#complete-test",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#complete-test",
    "title": "In-Class Excerise 4",
    "section": "Complete Test",
    "text": "Complete Test\n\ncheck_model(model1)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#see-method",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#see-method",
    "title": "In-Class Excerise 4",
    "section": "see method",
    "text": "see method\n\nplot(parameters(model1))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#ggstatsplot-method",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#ggstatsplot-method",
    "title": "In-Class Excerise 4",
    "section": "ggstatsplot method",
    "text": "ggstatsplot method\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#ggplot2-methods",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#ggplot2-methods",
    "title": "In-Class Excerise 4",
    "section": "ggplot2 methods",
    "text": "ggplot2 methods\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(a).html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(a).html",
    "title": "In-Class Excerise 5",
    "section": "",
    "text": "pacman::p_load(ggtern, plotly, tidyverse)\n\n\n\n\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(a).html#data-preparation",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(a).html#data-preparation",
    "title": "In-Class Excerise 5",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nCreating three new measures: young, active and old\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(a).html#plotting-ternary-diagram",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(a).html#plotting-ternary-diagram",
    "title": "In-Class Excerise 5",
    "section": "Plotting Ternary Diagram",
    "text": "Plotting Ternary Diagram\n\nCreating a plot with colored axis and arrows for ease of understanding.\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\nInteractive plot: Note that this cannot be converted this using ggplotly\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(b).html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05(b).html",
    "title": "In-Class Excerise 5",
    "section": "",
    "text": "Installing and Launching R Packages\n\npacman::p_load(seriation, dendextend, heatmaply, GGally, parallelPlot, tidyverse)\n\n\n\nImporting and Preparing The Data\n\nImporting data set\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nPreparing the data\n\nrow.names(wh) <- wh$Country\n\nTransforming the data frame into matrix\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\n\n\nHeatmap\n\nPlotting static heatmap\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nCreating interactive heatmap\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nClustering\n\nPlotting heatmap by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\ndend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nfind_k() is used to determine the optimal number of cluster\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nVisualising the clustering\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\nUsing Blue color paletter of rColorBrewer\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\nAdding plotting features to ensure cartographic quality:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\nParallel Coordinates Plot\n\nPlotting basic static parallel coordinates\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nAdding boxplot\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nLearning points:\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\n\nParallel coordinates with facet\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))\n\n\n\n\nPlotting Interactive Parallel Coordinates Plot\nBasic plot\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\nAdding histogram\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html",
    "title": "In-Class Excerise 6",
    "section": "",
    "text": "The data that is used in this in-class exercise is arrivals_by_air"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html",
    "title": "In-Class Excerise 7",
    "section": "",
    "text": "Map and Geographical Data\n\nWhen working on geographical data, understand the data and utilize the most appropriate geometry.\n\nCoordinates System\n\nGeographic coordinates system are in decimal places and is useful in providing precise location. However, it is not ideal for measuring distance\nProjected coordinates system has advantage that lengths (in meters), angles, and areas are constant across the two dimensions.\n\nQualitative Thematic Map\n\nUse of different shapes, hue, arrangement and orientation for different representation\nFor colour, values refers to different tones of grey. Saturation refers to same colour with different intensity. For different quantities, different saturation of the same colour can be used. Alternatively, different sizes can also meet the same intent.\n\nProportional Symbol Map\n\nUnderstanding how to size the circles: we should not double the diameter of the circles when the value is doubled but instead, we should double the area (increase in size is much smaller = misleading)\nArea representation should be consistent (e.g. we should not compare states of America against other countries as a whole).\nBricks map (wafer map in R) is an alternative method for proportional symbol map\n\nChoropleth Map\n\nShould not be confused with heatmap\n\n\n\nUnclassified choropleth map have a smooth, continuous gradient\nMap visualisation is affected by the number of classes as well as the method of classification used.\n\nEqual interval means that each class/bin has the same range\nQuantitle means each class have the same number of observations\n\nShould avoid multiple colours because it misleads the reader easily\n\nGeofacet\n\nPositions the graphs at their relative location\nHave to manually design the grid based on the map location"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#in-class-exercise-sg-pools",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#in-class-exercise-sg-pools",
    "title": "In-Class Excerise 7",
    "section": "In Class Exercise (SG Pools)",
    "text": "In Class Exercise (SG Pools)\n\n.shp file is the commonly used data file format for geospatial data (cannot be used alone)\n.kml is another commonly used data file format as well\n.geojson file is readable by notepad but it is not easily edittable\n\nAdding details to the map by using details\n\nAdding name to detail to bring out the Singapore map (better method than\n\n\nCreating a calculated field to rename 0 and 1 to Branch and Outlet\n\nAdding the channel to colours to enable more differentiation\n\nAdding Gp1Gp2Winn to see which are the popular outlets/branches\n\nChanging size, reducing opactity and adding border to improve visualisation\n\n\nEditting tooltip to show useful info\n\nXcoord and Ycoord are removed\n\n\nFinal visualisation for SGPools outlets with winning rates:"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#in-class-exercise-realis",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#in-class-exercise-realis",
    "title": "In-Class Excerise 7",
    "section": "In Class Exercise (Realis)",
    "text": "In Class Exercise (Realis)\nFor this exercise, we will use the csv file titled “ResidentialTransaction20220826195250”.\nWe will first remove the existing file that appear on the screen.\n\nNext, we will select the six residential files and drag them into create table. this allows Tableau to auto merge all the six tables on its own.\n\n\n\nAfter adding longitude and latitude, add postal code to details. Map of Singapore appears because tableau is linked to Onemap which enables it to read the postal code and identify its corresponding location.\n\n\n\nAdding more details to the charts: Project name, Number of units sold, and Sold price. Also adding filter for property type. Pin the map so the visualisation does not change when changing different filter which can be distracting for the readers.\n\nFinal visualisation for Property Resale Price in Singapore:"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#in-class-exercise-geospatial",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#in-class-exercise-geospatial",
    "title": "In-Class Excerise 7",
    "section": "In Class Exercise (Geospatial)",
    "text": "In Class Exercise (Geospatial)\nWe can make use of data.gov.sg to find geospatial data of Singapore\n\nWe will be adding the files ‘respopagesextod2022’ and ‘master-plan-2019-subzone-boundary-no-sea-geojson’ for this exercise. Join using the\n\nIf the subzone naming is not corrected, there would not be any differentiation in the map. This is because the naming mismatch due to case sensitive. We will resolve this by going to the data source type and change the naming of subzone using formula.\n\nIncreasing the population size classification by double clicking on the legend. Increase the number of steps to the desired number (in this case, we choose 10).\n\nThe final visualisation for Population size in Singapore:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wei Lun’s Visual Analytics Site",
    "section": "",
    "text": "This website is a portfolio of my work created as part of ISSS608 Visual Analytics and Applications course requirement.\nHope you enjoy the website!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "1. Overview\n\nAge-sex pyramid, also known as population pyramid, is an analytical visualization commonly used to reveal the distribution of a population by age group and gender. This take-home exercise aims to reveal the demographic structure in nine selected planning area of Singapore by using the population pyramid charts.\nThe dataset containing the demographics of Singapore residents for June 2022 was obtained from Department of Statistics. The data was then imported into Tableau desktop for data processing and visualisation.\n\n\n2. Design Sketch\n\n\n\n\n3. Data Wrangling\n\n3.1 Re-group AG into AG (10years)\nFrom the age group distribution in Singapore population, it can be observed that there is a big number of 19 bins where each bin covers an age range of 5 years. The bins may become narrow or compressed when fitted into a small-multiple plot which makes identifying of meaningful patterns challenging. Therefore, we re-group the age groups to cover a range of 10years to reduce the number of bins displayed.\n\n3.2 Creating male and female population variables\nA single population pyramid is made by two age group distributions for both genders in a population. The dataset used currently combines the population for both genders. Hence, two new variables (‘Male Pop’ & ‘Female Pop’) are created using ‘Calcuated Field’ to represent either male or female populations only.\n\n\n\n4. Population Pyramid\n\n4.1 Selection of 9 planning areas\nIn this exercise, we will be studying the demographics structure in 9 planning areas with the largest populations. Large populations are chosen to ensure that we can cover as many Singaporean residents as possible for the study. We can identify these areas using the population distribution by planning areas below.\n\n4.2 Final visualization\nThe 9 population pyramids are displayed in a single view using trellis display as shown below. This chart is also published on Tableau Public.\n\n\n\n5. Observations\n\nThe following are observations revealed by the above analytical visualization:\n\nAll nine planning areas have narrower base compared to the body which shows low birth rate as there are fewer number of children than adults.\nAll nine planning areas have almost symmetrical halves which suggests almost equal gender ratio.\nPunggol and Sengkang have considerable higher number of young children and teenagers (0 to 19 age groups) than other areas, likely due to the development of new flats in these areas.\nIndents at 30 to 49 age groups for Woodlands, Tampines and Choa Chu Kang signals an outflow of working adults out of these areas.\nBulge at 30 to 49 age groups for Punggol and Sengkang indicates an influx of working adults into these two planning areas.\nBedok and Tampines have the largest number of population of 50 to 69 age groups which suggests characteristics of mature estates.\nYishun has an overall barrel like structure compared to others suggesting a more balanced ratio of the young, middle-aged and the elderlies.\nFemales had a longer life expectancy than males in these areas as the female population are larger than male population for age group above 80 years old.\nAll nine planning areas have a distinct drop for 80 to 89 age group suggesting life expectancy to be in this range.\n\n\n\n6. Worksheet vs Dashboard\n\nWe can build a trellis display for nine population pyramids using multiple worksheets and compile into a dashboard (as shown above) or using a single worksheet (as shown below).\n\nWe will compare some advantages and disadvantages of each method.\nTrellis display (horizontal) in Worksheet\nAdvantages:\ni) Less steps required to build and has automated chart fitting and labeling.\nii) Easier to compare across the same age groups.\nDisadvantages:\ni) Requires several additional fields and complex equations to build a 3x3 grid.\nii) Pyramids are compressed to fit into the same display and could be misleading.\nTrellis display in Dashboard\nAdvantages:\ni) Larger space for each pyramids so they are not compressed.\nii) Able to custom layout to desired design without any coding.\nDisadvantages:\ni) Multiple worksheet adjustments are required for any changes to the pyramids.\nAfter considering the pros and cons, trellis display in dashboard is better suited for this exercise.\n\n\n7. Step-by-Step Instructions\n\n6.1 Data preparation\n\n\n\n\n\n\n\n\nNo.\nStep\nIllustration\n\n\n\n\n1.\nDownload csv file from Singstat website given in Section 1. Load the respopagesextod2022.csv file into Tableau Desktop by clicking ‘File’ followed by ‘Open’.\n\n\n\n2.\nClick on the drop-down arrow for ‘AG’, hover over ‘Create’ and click on ‘Group’. Create age groups in interval of 10 by grouping a pair of age groups with 5 years interval. Type ‘AG (10years)’ in ‘Field Name’ when new grouping is done.\n\n\n\n3.\nGo to ‘Analysis’ and click on ‘Create Calculated Field’. Overwrite ‘Calculation1’ with ‘Male Pop’ and typed in the following formula: IF [Sex] = “Males” THEN [Pop] END\nRepeat this step for ‘Female Pop’ with the following formula: IF [Sex] = “Females” THEN [Pop] END\n\n\n\n\n6.2 Creating population pyramids for 9 planning areas in dashboard\n\n\n\n\n\n\n\n\nNo.\nStep\nIllustration\n\n\n\n\n1.\nCreate a new worksheet ‘Pyramid (3Top)’. Click and drag ‘PA’, ‘Male Pop’ & ‘Female Pop’ from Data pane to Columns. Add ‘AG(10yrs)’ to Rows. Ensure summation of ‘Male Pop’ and ‘Female Pop’ are added.\n\n\n\n2.\nClick the dropdown arrow on PA beside ‘Columns’ and select ‘Filter’. Uncheck all except the 3 selected planning area. Click ‘Ok’ once done.\nHide field label for row ‘AG (10yrs) and column ’PA’.\n\n\n\n3.\nHover over AG(10yrs) on the chart. Click on the ‘AZ’ icon and sort the rows in descending order (0 to 9 at the bottom & 90 and over at the top)\nRight-click on one of the ‘Male Pop’ x-axis and select ‘Edit Axis’. Under Range, select ‘Fixed’ and set 0 as min and 30,000 as max. Under Scale, checked ‘Reversed’. Under Axis Titles, remove the title ‘Male Pop’. Close window once done.\nRight-click on one of the ‘Female Pop’ x-axis. Repeat the same steps as above for Range and Axis Titles only.\nUnder ‘Marks’, click on ‘Color’ under ‘Sum(Female Pop)’ ribbon. Select pink color to represent female population.\nSelect ‘Entire View’ under ‘Fit’. Your diagram should look similar to the diagram on the right.\n\n\n\n4.\nDuplicate ‘Pyramid (3Top)’ and renamed worksheets as ‘Pyramid (3Mid)’ and ‘Pyramid (3Btm)’. In new workshops, update ‘PA’ filter such that the remaining 6 planning areas are all included.\n\n\n\n5.\nClick on ‘New Dashboard’ at the bottom and rename it as ‘Dashboard (Trellis)’.\nUse floating objects and create a placeholders as shown in the diagram on the right.\n\n\n\n6.\nHold down shift and drag ‘Pyramid(3Top)’, ‘Pyramid (3Mid)’ and ‘Pyramid (3Btm)’ into the respective placeholders. Update the chart title and axis titles accordingly. The final diagram should look like the one on the right.\n\n\n\n\n6.3 Creating population pyramids for 9 planning areas in a single worksheet\n\n\n\n\n\n\n\n\nNo.\nStep\nIllustration\n\n\n\n\n1.\nCreate a new worksheet ‘Worksheet (Trellis)’. Click and drag ‘PA’, ‘Male Pop’ & ‘Female Pop’ from Data pane to Columns. Add ‘AG(10yrs)’ to Rows.\nClick the dropdown arrow on PA beside ‘Columns’ and select ‘Filter’. Uncheck all except the 9 selected planning area. Click ‘Ok’ once done.\n\n\n\n2.\nRepeat the same step as Section 6.2 Step 3, except use ‘Fit Width’. The diagram should look like the one on the right."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "1. Overview\n\nIn this take-home exercise, the task is to critique an original data visualisation of demographic structure for nine planning area in Singapore and create an alternate improved design by applying design principles and best practices.\nThe dataset used in this exercise is Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, june 2022. It is available at Department of Statistics, Singapore.\n\n\n2. Original Visualisation\n\nThe original visualisation contains three sections: (i) overall population pyramid (a.k.a age-sex pyramid), (ii) population pyramid by planning area (PA) and (iii) population pyramid by subzone. The live dashboard can be found in Tableau Public.\n\n\n\n\n\n\n\nOverall Population Pyramid\n\nPopulation Pyramid by Subzone\n\nPopulation Pyramid by Planning Area\n\n\n\n\n2.1 Clarity\na. Incomprehensible dashboard title: the term ‘Age Pyramid: Sex Pattern’ does not have the same meaning as age-sex pyramid. Readers might be confused with what the visualisations are trying to show.\nb. Chart titles have no lead-in or call-outs: It is good that reader is able to understand the reference country and time period from the chart title. However, it can be further improved with lead-in and call-outs to also explain the key trend or insights.\nc. Y-axis ticker labels are confusing: There is an unknown age group called ‘Null’ and the age range of each age group is represented using a solo number. Readers are not able to decipher what ‘Null’ age group, the age range of each group and whether the age group ‘80’ refers to 80 to 90 years old or 80years old and above.\nd. Source of data is missing: Missing recognition of data source could let the data visualisation lose credibility.\ne. Excess visulisation did not meet business intent: Excessive information is provided in this dashboard. Plotting of overall population pyramid, subzone population pyramids as well as all planning area population pyramids may lead readers away from the business intent of studying only nine planning areas.\nf. Instructions are provided on overview page: Readers are guided on how to use the interactive dashboard. This reduces confusion on how to use the interactive dashboard.\n2.2 Aesthetics\na. Congested and repeated x-axis labels: For planning areas and subzone pages, labels for the x-axis are clear but congested. Legend and color fill can be used to replace the congested labels and the need for repeated labels.\nb. X-axis between plots are not distinct: For planning areas and subzone pages, the x-axis looks like they run continuously and there are two ‘0K’ labels for the same plot. This makes it difficult to locate the axis.\nc. Visualisations do not fit into a single window: For planning areas and subzone pages, it is difficult to view and make comparison between population pyramids of different areas. The blanks in the charts does not value add to the visualisations.\nd. Missing horizontal grid lines: For planning areas and subzone pages, minor horizontal grid lines can be added for readers to read and compare the same age group across two areas.\nd. Chart title and x-axis title at the same level: On the overview page, readers may not be able to find the chart title for the bottom chart because it is on the same level as x-axis title.\ne. Dual y-axis: On the overview page, the y-axis in the middle for the bottom chart does not value-add. It would be able to remove it and reference the y-axis on the left.\n\n\n3. Alternative Visualisation\n3.1 Proposed design sketch\nSince the task is to study the demographic structures of nine planning areas, the proposed design do not need the overall population pyramid and the population pyramid by subzone since they provide excess information that might distract the readers from what is important. Hence, the proposed design will only contain one chart which is the population pyramids of nine planning areas.\n\n3.1 Clarity\na. Meaningful chart titles: The main title will be “Discovering Population Pyramid of 9 Most Populated Planning Areas in Singapore, June 2022” so the readers are able to understand the context of the visualisation immediately. The chart also have subtitle and commentary to provide additional clarity on the context and key observation.\nb. Right sized content: The visualisation do not contain excessive information that could distract the readers as explained at the start of this section. Also, only nine instead of all planning areas are plotted so readers know immediately which areas are the targets of comparison.\nc. Clear axes labels: Both axes titles are properly labelled so the readers know what each chart measures. For y-axis, the age groups are ordered from youngest at the bottom to oldest at the top per typical convention so readers can digest this information easily. For x-axis, there is no labels for male and female populations as they will be colour coded.\nd. Inclusion of data source at the bottom of the chart will provide credibility to the visualisation.\n3.2 Aesthetic\na. Use of legend and colour labels: The color shading and legend of the graph is used to identify the gender in each population pyramid. The intention of the colour is to help reader easily identify the gender directly from the chart without referring to the x-axis. It also helps to reduce congestion at the x-axis.\nb. Clear demarcation and gridlines: The charts do not share a continuous x-axis so readers can easily differentiate the axes for different planning area charts. Grid lines are also added so readers are able to make horizontal and vertical comparisons with ease.\nc. Smaller scale of x-axis major ticks: The scale of x-axis major tick marks are reduced to 5000 to show finer details and allow readers to identify smaller differences easily.\nd. Readable chart size: The size of the charts in the visualisation is configured such that all the bars within the population pyramids are readable and does not feel congested.\n\n\n4. Load Libraries and Dataset\nThe following code chunk is used to install the required R packages and load them onto R environment.\n\npacman::p_load(patchwork, ggthemes, hrbrthemes, ggrepel, plotly, tidyverse)\n\nNext, read_csv() from readr as part of tidyverse package is used to import the source file which is in csv file format.\n\n#To load dataset from .csv file\npopdata <- read_csv(\"Data/respopagesextod2022.csv\") \n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n5. Data Preparation\n5.1 Compute frequency count by Age Group, Sex and Planning Area\nFrequency count of the total population is computed based on planning area, sex and age group. As shown in code chunk below, groupby() is used to group data by defined parameters while summarise() counts the number of residents.\n\n#Summing residents based on planning area, age group and sex\npopdata <- popdata %>%\n                group_by(`PA`,`AG`,`Sex`) %>%\n                summarise('Count'= sum(`Pop`)) %>%\n                ungroup()\n\n`summarise()` has grouped output by 'PA', 'AG'. You can override using the\n`.groups` argument.\n\n\n5.2 Transform population data for males\nTo plot the male population on the left axis of the population pyramid, ‘Pop’ values of Males are converted to negative values using the ifelse() function in code chunk below.\n\n#Create variable for chart purposes\npopdata_plot <- popdata\n\n#If Sex = 'Males', population value becomes negative else remains unchanged\npopdata_plot$Count = ifelse(popdata_plot$Sex == 'Males',\n                     yes = -popdata_plot$Count,\n                     no = popdata_plot$Count\n                     )\n\n\n\n6. Visualisation\n6.1 Finding the top 9 most populated planning area\nAs the requirement is to study the demographic structures of nine planning area, we will be choosing the nine most populated planning area.\nThe code chunk below consists of three main steps to obtain our target areas: First, the frequency count is computed based on planning area only using groupby() then the list is sorted from largest to smallest count using arrange(desc()). The final step is to pick out the top nine planning area in the list, which are also the nine most populated areas using top_n().\n\n#This code chunk does the following:\n#Step1) Compute resident count by PA and sort count in descending order\n#Step2) Removes all but top 9 most populated PA\npopdata_top9 <- popdata %>%\n                  group_by(`PA`) %>%\n                  summarise('total'= sum(`Count`)) %>%        #Step1\n                  arrange(desc(`total`)) %>%                 \n                  top_n(9,wt=total) %>%                       #Step2\n                  ungroup()\n\n6.2 Trellis display of population pyramids for top 9 most populated planning area of Singapore\nFor this dataset, the age group is sorted alphanumerically which would not make sense for the population pyramid axis. Hence, we need to assign the correct order for this categorical variable.\nThis can be done by changing the order for age group variable using factor() with the factor levels.\n\n#Define the correct order for AG\nag_order <- c(\"0_to_4\", \"5_to_9\", \"10_to_14\", \"15_to_19\", \n                 \"20_to_24\", \"25_to_29\", \"30_to_34\", \"35_to_39\", \n                 \"40_to_44\", \"45_to_49\", \"50_to_54\", \"55_to_59\", \n                 \"60_to_64\", \"65_to_69\", \"70_to_74\", \"75_to_79\", \n                 \"80_to_84\", \"85_to_89\", \"90_and_over\")\n\n#Update order for AG column for popdata_plot dataframe\npopdata_plot$AG <- factor (popdata_plot$AG, level = ag_order)\n\nAn initial static plot is plotted using ggplot() and geom_col() from ggplot2 package. Then using facet_wrap, the population pyramids of 9 most populated planning areas are put into a 3 by 3 grid.\nscale_x_continuous() is used to configure the x-axis markers and ticker labels while labs() is used to add title and subtitle on top of the chart. Last but not least, the axis titles are updated using ylab() and xlab().\n\n#Using ggplot and facet_wrap to plot a trellis diagram of 9 population pyramid\np <- ggplot(subset(popdata_plot, PA %in% c(popdata_top9$PA)),\n        aes(x = Count, y= AG, fill = Sex)) +\n    geom_col() +\n    facet_wrap( ~PA, nrow = 3, ncol = 3) +\n    scale_x_continuous(limits = c(-15000,15000),              #format x-axis\n                       breaks = seq(-15000, 15000, 5000),\n                       labels = paste0(as.character(c(seq(15, 0, -5),\n                                                      seq(5, 15, 5))),\"K\"))\n\n#Formatting axis and adding chart title and subtitle\np + labs(title=\"Discovering Population Pyramid of 9 Most Populated Planning Areas in Singapore, June 2022\", \n         subtitle=\"Distinct differences in demographic structures of north-east vs west planning areas of Singapore\",\n         caption=\"Source: Department of Statistics, Singapore (SingStat)\") +\n  theme(plot.title = element_text(color = \"black\", size = 20, face = \"bold\")) +\n  ylab(\"Age Groups\") +\n  xlab(\"Population\") +  \n  theme_bw()        \n\n\n\n\n\n\n7. Reflection\nMy main challenge when attempting this take-home exercise is not being proficient in using the correct R packages. With suitable packages and functions, more analytical layers can be applied to the chart object to better serve the user needs. For example, I would like to add relevant statistical parameters such as mean male and female population of the nine planning areas for each age group as a vertical line in each nine plots to provide some ease of comparison for the readers.\nFuture work can be done to enhance the population pyramid chart. An example is using plotly package, where a tooltip can help users identify the stats of each bar in the pyramid without labelling all the charts."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "This exercise aims to unveil the salient patterns in the resale prices of public housing property based on different residential towns and estates through analytical visualization. Appropriate visualization and interactive techniques are applied to enhance users’ data discovery experiences.\nIn this study, the focus is on 3, 4 and 5 room housing types for the year of 2022.\nThe dataset used was retrieved from Data.gov.sg, titled Resale flat princes based on registration date from Jan-2017 onwards. The source file is in csv format."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "title": "Take-home Exercise 3",
    "section": "2. Loading R Packages",
    "text": "2. Loading R Packages\n\nThe following packages and required libraries are loaded in this exercise:\n\npacman::p_load(ggstatsplot, ggiraph, plotly, performance, nortest, patchwork, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataset",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataset",
    "title": "Take-home Exercise 3",
    "section": "3. Dataset",
    "text": "3. Dataset\n\n3.1 Import dataset\n\n#Import dataset from .csv file\nHDBdata <- read_csv(\"Data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\", show_col_types = FALSE)\n\n#ReView data\nhead(HDBdata, n=5)\n\n# A tibble: 5 × 11\n  month   town     flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n  <chr>   <chr>    <chr>   <chr> <chr>   <chr>     <dbl> <chr>     <dbl> <chr>  \n1 2017-01 ANG MO … 2 ROOM  406   ANG MO… 10 TO …      44 Improv…    1979 61 yea…\n2 2017-01 ANG MO … 3 ROOM  108   ANG MO… 01 TO …      67 New Ge…    1978 60 yea…\n3 2017-01 ANG MO … 3 ROOM  602   ANG MO… 01 TO …      67 New Ge…    1980 62 yea…\n4 2017-01 ANG MO … 3 ROOM  465   ANG MO… 04 TO …      68 New Ge…    1980 62 yea…\n5 2017-01 ANG MO … 3 ROOM  601   ANG MO… 01 TO …      67 New Ge…    1980 62 yea…\n# … with 1 more variable: resale_price <dbl>, and abbreviated variable names\n#   ¹​flat_type, ²​street_name, ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model,\n#   ⁶​lease_commence_date, ⁷​remaining_lease\n\n\n3.2 Data Preparation\nFrom the data review in the earlier step, we want to converting month to date format to do more meaningful analysis. This is done using as.Date() as shown in the code chunk below:\n\n#Appending an artifical day to convert month into date format\nHDBdata$month <- paste(HDBdata$month,\"01\", sep = \"-\") %>%\n  as.Date(HDBdata$month, format = \"%Y-%m-%d\")\n\nAs the dataset contains information that is outside the scope of our studies. We can extract the relevant housing type and time period by using filter() function.\n\n#Filtering the dataset based on time range and flat types\nHDBdata2022 <- HDBdata %>% filter(month>\"2021-12-01\" & month<\"2023-01-01\") %>%\n  filter(flat_type %in% c(\"3 ROOM\",\"4 ROOM\",\"5 ROOM\"))\n\n3.3 Data Wrangling\nIn Singapore, HDB owners only have the ownership rights to their flats for a limited period of time due to 99-year lease. Upon the expiry of their leases, the flats will be reverted to HDB and the land will be surrendered to the State. Hence, we would want to convert remaining lease to numeric data type for further analysis since it could potentially influence the resale price.\n\nHDBdata2022$remaining_lease_month = as.numeric(substr(HDBdata2022$remaining_lease,10,11))\nHDBdata2022$remaining_lease_month = ifelse(is.na(HDBdata2022$remaining_lease_month),\n                                           yes = 0,\n                                           no = HDBdata2022$remaining_lease_month)\n\nHDBdata2022$remaining_lease = as.numeric(substr(HDBdata2022$remaining_lease,1,2))+\n  (HDBdata2022$remaining_lease_month/12)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualisation",
    "title": "Take-home Exercise 3",
    "section": "4. Visualisation",
    "text": "4. Visualisation\n\n4.1 General Exploratory Data Analysis (EDA)\nIn the first part of our exploratory data analysis, we will visualise data from the cleaned data set to understand the general trends in the property market of 2022. Starting from a broader perspective, we would be able to narrow down the specific areas to focus on in the next stage.\n4.1.1 Price trend of 3-, 4- and 5-room type in Year of 2022\nFirst, we will explore the general price trend over the course of the year. An interactive plot was created using plot_ly() to allow users to read the average resale price easily with the tooltip. The tooltip content was edited using the hovertemplate() function.\n\n# Find the average resale price grouped by month, flat type\nHDBdata2022_ave <- HDBdata2022 %>%\n  group_by(`month`, `flat_type`) %>%\n  summarise(ave_price = mean(resale_price)) %>%\n  mutate(new_date = format(month, \"%h %Y\"))\n\n# Create an interactive plot\nplot_ly(\n  data = HDBdata2022_ave, \n  x = ~month, y = ~ave_price,\n  color = ~flat_type,\n  type = 'scatter', mode = 'line',\n  hovertemplate = ~paste(\"Month:\", new_date,\n                         \"<br>Average Resale Price($k):\", round(ave_price/1000, digits=0))) |>\n#Configure title and axes\n  layout(title = \"Average Resale Price in 2022 for 3-, 4-, 5-Room Flat Type\",\n         xaxis = list(title = \"\"),\n         yaxis = list(title = \"Average Resale Price($)\", range = c(350000,700000)))\n\n\n\n\n\nObservations:\n\nAll three flat types average resale price by the end of 2022 had increased above the resale price at the start of the year.\nThe overall percentage increase in resale price for 2022 were 6.17%, 7.05% and 5.74% for 3, 4 and 5 room flat type respectively.\nThe price difference between 3- and 4- room flat type was in general larger than the price difference between 4- and 5- room flat types for the whole of 2022.\nTaking a deeper look on the trend, we can also notice that the resale price for all three flat types had declined slightly from Oct’22.\n\n4.1.2 Total transaction volume for all flat types in each town\nWith bubble plot, we can visualise up to 3 parameters and up to 4 parameters with the use of colours in a single chart. By making the chart interactive, we can also isolate the towns based on our scope of analysis.\n\n#Count number of transactions in each town\nHDBdata2022_trans <- HDBdata2022 %>%\n  group_by(`town`) %>%\n  summarise(volume = n(), \n         ave_price = mean(resale_price/1000), \n         ave_remain_lease = mean(remaining_lease)) %>%\n  arrange(desc(volume)) %>%\n  mutate(town = factor(town,town))\n\n#Plot a bubble chart\np <- HDBdata2022_trans %>%\n  \n#prepare text for tooltip\n  mutate(text = paste(town, \n                      \"<br>Ave Resale Price ($k): \", round(ave_price,\n                                                           digits=0), \n                     \"<br>Ave Remaining Lease (Yr): \", round(ave_remain_lease,\n                                                          digits=0),\n                      \"<br>Transaction Vol: \", volume)) %>%\n# Basic Plot\n  ggplot(aes(x = ave_remain_lease, y = ave_price, \n             size = volume, color = town, text = text)) +\n  geom_point(alpha = 0.6) + \n  scale_size(range = c(2, 20)) +\n  scale_x_continuous( limits = c(50, 100)) +\n  scale_y_continuous( limits = c(400, 800)) +\n  theme_minimal()\n\nggplotly(p, tooltip=\"text\") %>%\n  layout(title = 'Characteristics across Towns, 2022',\n         xaxis = list(title = 'Average Remaining Lease (Yr)'), \n         yaxis = list(title = 'Average Resale Price ($k)'),\n         legend = list(title=list(text='<b> Town </b>')))\n\n\n\n\n\nObservations:\n\nDifferent towns can have significantly different transaction volume and resale price, which suggests some towns are more preferred by buyers.\nIt can be observed that highest transacted towns tend to have the longer remaining lease while the lowest transacted towns have shorter remaining lease. This might suggest towns with newer flats, i.e. longer remaining lease, may have higher chance of selling their flats.\nIt is also noted that the most expensive flats do not come from towns with the largest transaction or have the longest remaining lease. Hence, it is worth exploring what are the factors that correlate with the resale price.\n\n4.1.3 Distribution of flat types in each town\n\np_bar <- ggplot(data=HDBdata2022, aes(x = after_stat(count), y = town, fill = flat_type)) +\n  geom_bar(position = \"fill\", stat = \"count\")\n\n\nggplotly(p_bar) %>%\n  layout(title = 'Distribution of Flat Types in each Town, 2022',\n         xaxis = list(title = 'Town'), \n         yaxis = list(title = 'Count'),\n         legend = list(title=list(text='<b> Flat Type </b>')))\n\n\n\n\n\nObservations\n\nThere is a significantly different proportion of 3-, 4- and 5-room in each town. Therefore, the use of average resale price of each town may not reveal the minute relationships. In the next section, we will explore and test the observations found between resale price and the respective factors.\n\n\n\n4.2 Resale Price and Relevant Factors EDA\nIn this section, we will assess the impacts of various individual factors on resale price.\n4.2.1 HDB flats located near the central region of Singapore can fetch higher resale prices\nTo explore the resale prices of the flats, box plots are used to visualise the pattern between continuous data type (resale prices) and categorical data type (towns).\n\nHDBdata2022_region <- HDBdata2022 %>%\n  mutate(region = case_when(town %in% c(\"ANG MO KIO\", \"HOUGANG\", \"PUNGGOL\", \"SERANGOON\", \"SENGKANG\") ~ \"North-East\",\n            town %in% c(\"BISHAN\", \"BUKIT MERAH\", \"BUKIT TIMAH\", \"CENTRAL AREA\",\n                         \"GEYLANG\", \"KALLANG/WHAMPOA\", \"MARINE PARADE\", \"QUEENSTOWN\", \"TOA PAYOH\") ~ \"Central\",\n            town %in% c(\"BEDOK\", \"PASIR RIS\", \"TAMPINES\") ~ \"East\",\n            town %in% c(\"SEMBAWANG\", \"WOODLANDS\", \"YISHUN\") ~ \"North\",\n            town %in% c(\"BUKIT BATOK\", \"BUKIT PANJANG\", \"CHOA CHU KANG\", \"CLEMENTI\", \"JURONG EAST\", \"JURONG WEST\") ~ \"West\"))\n\n\nplot_ly(data = HDBdata2022_region,\n        x = ~town, y = ~resale_price,\n        type = \"box\",\n        color = ~region) %>%\n  \n  layout(title = \"Resale Price vs Town, 2022\",\n         xaxis = list(title = \"Town\"),\n         yaxis = list(title = \"Resale Price($)\"))\n\n\n\n\n\nObservations:\n\nThe median resale prices of HDB flats located in central region are higher than the rest of the regions in Singapore.\n\nTo test this observation, the following null hypothesis were tested:\nH0: The median resale price for different towns are the same.\nH1: The median resale price for different towns are different.\nA random sample where one town is picked from each region is used for One-way ANOVA test. The chosen towns are Central Area, Bedok, Yishun, Serangoon and Clementi.\n\np_town <- HDBdata2022_region %>% \n  filter(town %in% c(\"CENTRAL AREA\", \"BEDOK\", \"YISHUN\", \"SERANGOON\", \"CLEMENTI\")) %>%\n  ggbetweenstats(\n    x = town, y = resale_price,\n    type = \"nonparametric\",\n    mean.ci = TRUE, \n    pairwise.comparisons = TRUE, \n    pairwise.display = \"ns\",\n    p.adjust.method = \"fdr\",\n    messages = FALSE,\n    xlab = \"Town\",\n    ylab = \"Resale Price ($)\",\n    title = \"One-way ANOVA (Random Sample)\"\n  )\n\np_town\n\n\n\n\nFrom the test results, we can observe that other than clementi (West) and serangoon (North-East), the median is proven statiscally to be different across towns in the other regions.\n4.2.2 HDB flats with larger floor area have higher average resale prices\nIntuitively, we expect larger flats will have higher resale price as the purchase price was already higher. However, we can use the data from HDB to test our basis using the transaction data in Year 2022 as shown below.\n\nplot_ly(\n  data = HDBdata2022, \n  x = ~floor_area_sqm, y = ~resale_price,\n  color = ~flat_type,\n  type = 'scatter', mode = \"markers\",\n  hovertemplate = ~paste(\"Floor Area (sqm):\", floor_area_sqm,\n                         \"<br>Resale Price($M):\", round(resale_price/1000000,\n                                                        digits=2))) |>\n#Configure title and axes\n  layout(title = \"Resale Price vs Floor Area, 2022\",\n         xaxis = list(title = \"Floor Area (sqm)\"),\n         yaxis = list(title = \"Resale Price($)\"))\n\n\n\n\n\nObservations:\n\nThe first observation is that the average resale prices increases as the floor area increases.\nThe second observation is the each flat type can be classified by distinct floor area range.\n\nTo test the first observation, the following null hypothesis were tested:\nH0: The average resale price for different floor areas are the same.\nH1: The average resale price for different floor areas are different.\n\n#check for normality using Anderson-Darling\nad.test(HDBdata2022$floor_area_sqm)\n\n\n    Anderson-Darling normality test\n\ndata:  HDBdata2022$floor_area_sqm\nA = 320.42, p-value < 2.2e-16\n\n\nThe Anderson-Darling test output suggest that there is sufficient evidence statistically to reject the null hypothesis that floor area is normally distributed. Therefore, a non-parametric test is used in ggscatterstats() to build a visual for Significant Test of Correlation between Resale Price and Floor Area.\n\nggscatterstats(\n  data = HDBdata2022,\n  x = floor_area_sqm,\n  y = resale_price,\n  type = \"nonparametric\",\n  marginal = TRUE,\n  title = \"Significant Test of Correlation\",\n  xlab = \"Floor Area (sqm)\",\n  ylab = \"Resale Price ($)\"\n)\n\n\n\n\nAs the test reveals that p-value is less than 𝞪-value, there is sufficient statistical evidence to reject the null hypothesis and conclude that the average resale price between different flat areas are different.\nAlso, we can conclude intuitively as well as statically that more rooms flat type will fetch higher resale price since each flat type belongs to a relatively distinct floor area range.\n4.2.3 HDB flats with higher storey ranges have higher average resale prices\n\ntooltip <- function(y, ymax, accuracy = 1) {   #<<\n  mean <- scales::number(y, accuracy = accuracy) #<<\n  sem <- scales::number(ymax - y, accuracy = accuracy) #<<\n  paste(\"Average Resale Price($k):\", mean, \"+/-\", sem) #<<\n} #<<\n\ngg_point <- ggplot(data=HDBdata2022, \n                   aes(x = storey_range),\n) +\n  stat_summary(aes(y = resale_price/1000, \n                   tooltip = after_stat(  #<<\n                     tooltip(y, ymax))),  #<<\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #<<\n    fill = \"Grey\"\n  ) +\n  stat_summary(aes(y = resale_price/1000),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, linewidth = 0.2\n  ) +\n  coord_flip() +\n  labs(title=\"Average Resale Price vs Storey Range, 2022\") +\n  ylab(\"Average Resale Price ($k)\") +\n  xlab(\"Storey Reange\") +  \n  theme_minimal()        \n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nObservations:\n\nIt can be observed that the average resale prices for HDB flats increases as the storey ranges increases. This could be due to homeowners wish to stay higher so they are further away from the noise pollution from the roads and human traffic at the ground level.\nAnother point to note is that the range of the resale price is smaller at the lower storey ranges. This could be due to lower demand, partly caused by the requirements that a minority ethic group can only sell their home to another minority ethic group.\n\n4.2.3 HDB flats models do not show distinct relationship with resale prices\n\np_boxplot <- HDBdata2022 %>%\n  ggplot(aes(x = flat_model, y = resale_price)) + \n  geom_boxplot(aes(fill = flat_type)) +\n  coord_flip()\n\nggplotly(p_boxplot) %>%\n  layout(title = 'Flat Model vs Resale Price, 2022',\n         xaxis = list(title = 'Resale Price'), \n         yaxis = list(title = 'Flat Model'),\n         legend = list(title=list(text='<b> Flat Type </b>')))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "title": "Take-home Exercise 3",
    "section": "5. Conclusion",
    "text": "5. Conclusion\nFrom the overall trends, we had observed that overall HDB flat resale prices were on a rise in the year 2022. Towns with newer flats (i.e. longer remaining lease period) generally have higher transaction volume than those with older flats. Diving deeper into factors that could impact resale price, we tested and proven that the median resale prices in the central region are higher than the rest and the mean resale price increases with larger floor area.\nIf given more time, there are many opportunities to further explore this data set. They include statistically testing on resale price and storey level range and remaining lease as well as visualisation of uncertainty in using price averages in Section 4.1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/unpublished.html",
    "href": "Take-home_Ex/Take-home_Ex04/unpublished.html",
    "title": "Take-home Exercise 4",
    "section": "",
    "text": "For this exercise, I will be using various time-series data analytical visualization methods to explore the effects of COVID-19, as well as the global economic and political environment in 2022, on Singapore’s bilateral trade, including import, export, and trade balance.\nThe Merchandise Trade data is in .xlxs format and retrieved from the Department of Statistics, Singapore (DOS) website, under the sub-section of Merchandise Trade by Region/Market. The study period is between January 2020 to December 2022."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/unpublished.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex04/unpublished.html#loading-r-packages",
    "title": "Take-home Exercise 4",
    "section": "2. Loading R Packages",
    "text": "2. Loading R Packages\n--> Talk about what each package does\n\n\nShow the code\npacman::p_load(readxl, scales, viridis, lubridate, gridExtra, knitr, data.table, ggthemes, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/unpublished.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex04/unpublished.html#data-preparation",
    "title": "Take-home Exercise 4",
    "section": "3. Data Preparation",
    "text": "3. Data Preparation\n3.1 Data Import\nThe function read_excel() is used to read the downloaded .xlsx file. The arguments included are path to the excel file, col_types = NULL to guess the data type for the column and range to define the rows and columns where data is extracted. By selecting specific rows and columns, we can reduce some data processing steps compared to importing all rows and columns.\n\n\nShow the code\n# Read the Excel file and select the relevant columns and rows\nimports <- read_excel(\"data/outputFile.xlsx\", col_types = NULL, range = \"T1!A10:AL129\")\nexports <- read_excel(\"data/outputFile.xlsx\", col_types = NULL, range = \"T2!A10:AL101\")\n\n# Review data\nimports\n\n\n# A tibble: 119 × 38\n   `Data Series` 2023 …¹ 2022 …² 2022 …³ 2022 …⁴ 2022 …⁵ 2022 …⁶ 2022 …⁷ 2022 …⁸\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Total Mercha…  4.44e7  4.99e7  5.07e7  5.32e7  5.58e7  5.85e7  6.10e7  5.96e7\n 2 America (Mil…  6.27e3  6.90e3  7.53e3  7.67e3  8.00e3  8.63e3  7.88e3  8.02e3\n 3 Asia (Millio…  3.02e4  3.36e4  3.47e4  3.61e4  3.77e4  4.09e4  4.32e4  4.25e4\n 4 Europe (Mill…  6.43e3  7.54e3  7.24e3  7.48e3  8.17e3  7.43e3  8.30e3  7.30e3\n 5 Oceania (Mil…  9.83e2  1.40e3  6.64e2  1.33e3  1.54e3  9.36e2  1.06e3  1.14e3\n 6 Africa (Mill…  5.41e2  4.15e2  4.84e2  5.90e2  3.95e2  5.51e2  5.74e2  6.76e2\n 7 European Uni…  4.58e3  5.06e3  4.96e3  4.69e3  5.15e3  5.13e3  5.23e3  5.14e3\n 8 Belgium (Tho…  9.41e4  1.04e5  1.22e5  8.88e4  2.16e5  1.33e5  2.25e5  1.15e5\n 9 Denmark (Tho…  5.75e4  6.77e4  6.74e4  6.37e4  6.18e4  1.26e5  5.58e4  5.10e4\n10 France (Thou…  1.61e6  1.54e6  1.56e6  1.49e6  1.66e6  1.62e6  1.56e6  1.54e6\n# … with 109 more rows, 29 more variables: `2022 May` <dbl>, `2022 Apr` <dbl>,\n#   `2022 Mar` <dbl>, `2022 Feb` <dbl>, `2022 Jan` <dbl>, `2021 Dec` <dbl>,\n#   `2021 Nov` <dbl>, `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>,\n#   `2021 Jul` <dbl>, `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>,\n#   `2021 Mar` <dbl>, `2021 Feb` <dbl>, `2021 Jan` <dbl>, `2020 Dec` <dbl>,\n#   `2020 Nov` <dbl>, `2020 Oct` <dbl>, `2020 Sep` <dbl>, `2020 Aug` <dbl>,\n#   `2020 Jul` <dbl>, `2020 Jun` <dbl>, `2020 May` <dbl>, `2020 Apr` <dbl>, …\n\n\nShow the code\nexports\n\n\n# A tibble: 91 × 38\n   `Data Series` 2023 …¹ 2022 …² 2022 …³ 2022 …⁴ 2022 …⁵ 2022 …⁶ 2022 …⁷ 2022 …⁸\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Total Mercha…  4.96e7  5.50e7  5.42e7  5.66e7  6.25e7  6.34e7  6.41e7  6.42e7\n 2 America (Mil…  5.82e3  6.22e3  6.39e3  6.65e3  7.09e3  7.93e3  6.73e3  7.51e3\n 3 Asia (Millio…  3.46e4  3.97e4  3.80e4  4.05e4  4.56e4  4.41e4  4.61e4  4.63e4\n 4 Europe (Mill…  5.38e3  4.92e3  5.03e3  5.12e3  5.16e3  6.11e3  6.25e3  5.46e3\n 5 Oceania (Mil…  2.84e3  3.03e3  3.24e3  3.11e3  3.45e3  3.61e3  3.92e3  3.67e3\n 6 Africa (Mill…  8.76e2  1.09e3  1.53e3  1.19e3  1.20e3  1.61e3  1.10e3  1.21e3\n 7 European Uni…  4.54e3  4.14e3  4.24e3  4.30e3  4.07e3  5.02e3  5.50e3  4.61e3\n 8 Belgium (Tho…  8.73e5  4.32e5  7.57e5  3.51e5  3.87e5  5.71e5  9.92e5  5.89e5\n 9 Denmark (Tho…  2.71e4  3.11e4  2.92e4  6.73e4  4.48e4  4.28e4  4.86e4  3.43e4\n10 France (Thou…  5.02e5  4.02e5  3.24e5  5.30e5  3.59e5  4.54e5  4.59e5  4.25e5\n# … with 81 more rows, 29 more variables: `2022 May` <dbl>, `2022 Apr` <dbl>,\n#   `2022 Mar` <dbl>, `2022 Feb` <dbl>, `2022 Jan` <dbl>, `2021 Dec` <dbl>,\n#   `2021 Nov` <dbl>, `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>,\n#   `2021 Jul` <dbl>, `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>,\n#   `2021 Mar` <dbl>, `2021 Feb` <dbl>, `2021 Jan` <dbl>, `2020 Dec` <dbl>,\n#   `2020 Nov` <dbl>, `2020 Oct` <dbl>, `2020 Sep` <dbl>, `2020 Aug` <dbl>,\n#   `2020 Jul` <dbl>, `2020 Jun` <dbl>, `2020 May` <dbl>, `2020 Apr` <dbl>, …\n\n\n3.2 Data Preparation\n3.2.1 Check for missing values\nNext, the tables are being checked for missing values using a combination of functions any() and is.na(). If the result is FALSE, it means that there is no missing values.\n\n# Check for missing values\nprint(any(is.na(imports)))\n\n[1] FALSE\n\nprint(any(is.na(exports)))\n\n[1] FALSE\n\n\n3.2.2 Remove 2023 Jan column\nSince there study period covers from January 2020 to December 2022, the 2023 Jan column is removed from both imports and exports tables using indexing with a negative sign as shown below.\n\n# Remove 2023 Jan column from imports and exports\nimports <- imports[, -c(2)]\nexports <- exports[, -c(2)]\n\n3.2.3 Reducing number of columns\n\n# Rotating the tables to consolidate the months in a column\nimports_long <- imports %>%\n  pivot_longer(cols = c(2:37),\n               values_to = \"imports\")\nexports_long <- exports %>%\n  pivot_longer(cols = c(2:37),\n               values_to = \"exports\")\n\n# Correcting the column titles\nnames(imports_long)[names(imports_long) == \"Data Series\"] <- \"location\"\nnames(imports_long)[names(imports_long) == \"name\"] <- \"monthyear\"\nnames(exports_long)[names(exports_long) == \"Data Series\"] <- \"location\"\nnames(exports_long)[names(exports_long) == \"name\"] <- \"monthyear\"\n\ncreating a com\n\n# Creating a combined table\ntrades <- merge(imports_long, exports_long, by=c(\"location\",\"monthyear\"))\n\nDesign Sketch\nData Visualisation\nGraph 1: Heatmap: max import and export\nGraph 2: slope graph: changes the most in the year"
  }
]